# 네트워크 IO와 자원 효율

- 서버 프로그램은 기본적으로 네트워크 프로그램
- 다양한 구성 요소와 네트워크를 통해 데이터를 주고받음
- 보통 입출력에 소요되는 시간은 코드를 실행하는 시간보다 훨씬 길다.
- 서버처럼 네트워크 연동이 많은 프로그램은 전체 실행 시간의 90%이상을 입출력 대기에 사용하는 경우도 있다

**네트워크를 통해 데이터를 주고받는 과정**

```jsx
outputStream.write(...) // 출력 스트림으로 데이터 보내기
inputStream.read(...) // 입력 스트림으로 데이터 받기
```

> 블로킹
작업이 완료될 때 까지 스레드가 대기하는 것.
주로 데이터 입출력과정에서 발생, 입출력 과정에서 블로킹이 발생하기 때문에 블로킹IO라고도 함.
>

## 스레드

- 스레드가 대기하는데 시간을 소요한다는 것은 스레드를 실행하는 CPU도 아무것도 하지 않는 시간이 생긴다는 의미
- CPU 사용률을 높히려면 CPU가 실행할 스레드를 많이 만들면 된다.
- 요청당 스레드 방식으로 구현한 서버가 이에 해당
    - 동시에 실행되는 스레드 개수를 늘려 IO대기에 따른 CPU 낭비를 줄일 수 있다.
- 하지만 스레드를 생성하는 데에는 한계가 있음.
    - 사용자가 증가하면 메모리가 병목이 됨.

### 스레드가 많아졌을때의 문제

- 스레드를 많이 만들게 되더라도 컨텍스트 스위칭에 따른 문제가 생김
- 스레드가 증가하면 컨텍스트 스위칭에 사용되는 시간도 증가됨.
- 컨텍스트 스위칭에 들어가는 시간은 짧기만 동시 실행되는 스레드가 많아지면 CPU 효율에 영향을 준다.

**컨텍스트 스위칭**

- 운영체제는 여러 스레드를 번갈아 가면서 CPU에 할당
- CPU가 스레드를 전환하려면 현재 실행중인 스레드의 상태를 기록하고 다음에 실행할 스레드의 상태정보를 불러와야 함.
- 이렇게 상태 정보를 변경하고 스레드를 전환하는 과정을 컨텍스트 스위칭 이라고 함.
- 컨텍스트 스위칭은 마이크로초 단위로 실행되지만 컨텍스트 스위칭을 하는동안 CPU는 실질적인 작업을 하지 않음.
    - 때문에 동시에 실행되는 프로세스와 스레드가 많으면 컨텍스트 스위칭에 소요되는 시간도 무시하기 힘들다.

### 트래픽이 증가하면 자원 효율이 떨어지는 2가지 이유

1. IO 대기와 컨텍스트 스위칭에 따른 CPU 낭비
2. 요청마다 스레드를 할당함으로써 메모리 사용량이 높음.

### 서버 성능을 높히기 위해 자원 효율을 높히는 방법

- IO대기로 인한 CPU 낭비를 줄이고 요청을 처리하는 데 필요한 메모리를 줄이는 것.
1. 가상 스레드나 고루틴 같은 경량 스레드 사용
2. 논블로킹 또는 비동기 IO 사용

# 가상 스레드로 자원 효율 높이기

### CPU 효율 높일 수 있는 방법

- 코드를 블로킹 IO로 작성했는데 입출력 동안 스레드가 대기하지 않고 다른 일을 수행하도록
    - CPU 유휴시간이 줄어들고 더 많은 작업을 처리할 수 있게 된다.
    - 개발자는 성능을 높이기 위해 별도의 기술을 쓰지 않아도 된다.
- 자바의 가상 스레드나 GO 언어의 고루틴을 사용하는 것.

### 경량 스레드

- OS가 관리하는 스레드가 아니라 JVM 같은 언어의 런타임이 관리하는 스레드
- OS가 CPU로 실행할 스레드를 스케줄링하듯 언어 런타임이 OS 스레드로 실행할 경량 스레드를 스케줄링한다.
- OS 스케줄러에 의해 여러 스레드를 번갈아 실행하는 것처럼 플랫폼 스레드도 JVM 스케줄러에 의해 여러 가상 스레드를 번갈아 실행
- JVM은 기본적으로 풀에 CPU 코어 개수만큼 플랫폼 스레드를 생성하고 필요에 따라 플랫폼 스레드를 증가시킨다.

### 경량 스레드라고 부르는 이유

- 플랫폼 스레드보다 더 적은 자원을 사용
- 가상 스레드는 플랫폼 스레드보다 더 적은 메모리를 사용
- 스레드를 생성하는 시간도 많이 차이가 남.
- 가상 스레드는 플랫폼 스레드에 비해 훨씬 적은 비용(자원, 시간)
- 톰캣처럼 요청별 스레드를 생성하는 서버에서 가상 스레드를 사용하면 더 적은 메모리로 더 많은 요청을 처리할 수 있다.

**캐리어 스레드**

- 가상 스레드를 실행하는 플랫폼 스레드를 캐리어 스레드라고 표현
- CPU가 여러 스레드를 실행하는 것처럼 한 개의 캐리어 스레드도 여러 가상 스레드를 실행하게 된다.
- 특정 가상 스레드가 특정 캐리어 스레드에 연결되는 것을 **마운트**라고 표현
- 가상 스레드가 캐리어 스레드에 마운트 되면 가상 스레드가 실행 반대로 가상 스레드가 캐리어 스레드로부터 언마운트 되면 가상 스레드는 실행을 멈춤.

### 네트워크 IO와 가상 스레드

- 가상 스레드는 실행하는 과정에서 블로킹되면 플랫폼 스레드와 언마운트되고 실행이 멈춤
- 언마운트된 플랫폼 스레드는 실행 대기중인 다른 가상 스레드와 연결된 뒤 실행을 재개

![img_10.png](img/img_10.png)

**블로킹 연산과 synchronized**

- 블로킹 연산에는 IO 기능, ReentrantLock, Thread.sleep() 등이 포함
- 가상 스레드가 블로킹되면 플랫폼 스레드는 대기중인 다른 가상 스레드를 실행
- 자바 23또는 이전 버전에서 synchronized로 인해 블로킹되면 가상 스레드는 플랫폼 스레드로부터 언마운트 되지 않음 즉, 플래폼 스레드도 같이 블로킹됨.
    - 가상 스레드가 플랫폼 스레드까지 블로킹할 때 이를 가상 스레드가 플랫폼 스레드에 고정됐다고 함.
- 자바 21기준 synchronized 외에도 JNI 호출 등 가상 스레드가 플랫폼 스레드에 고정되는 경우가 있는데 가상 스레드가 고정되면 CPU 효츌을 높일 수 없다.

### 가상 스레드와 성능

- 가상 스레드는 IO 중심 작업일 때 효과가 있다.
- IO는 가상 스레드가 지원하는 블로킹 연산이므로, IO 중심 작업일 때 플랫폼 스레드가 CPU 낭비 없이 효율적으로 여러 가상 스레드를 실행할 수 있다.
- IO 중심 작업이라고 해서 무조건 가상 스레드의 이점을 얻는 것은 아님, 스케줄링에 사용되는 플랫폼 스레드 개수보다 가상 스레드의 개수가 많아야 효과를 기대할 수 있다.

**가상 스레드와 스레드 풀**

**요청별 스레드 방식을 사용하는 서버는 스레드 풀을 사용하는 경우가 많다.**

- 미리 스레드를 생성해서 요청이 들어왔을 때 스레드 생성 부하를 줄이기 위함.
- 스레드 풀 크기에 최대치를 설정해서 요청이 급격히 늘어나도 스레드가 무한정 생성되는 것을 방지
- CPU와 메모리 같은 자원을 일정 수준으로 제한해 서버 자원이 포화되는 것을 방지하려는 목적

**가상 스레드는 스레드 생성비용이 플랫폼 스레드보다 적기 때문에 스레드 풀을 미리 구성할 필요가 없다.**

필요한 시점에 가상 스레드를 생성하고 필요 없으면 제거하면 된다.

# 논블로킹 IO로 성능 더 높이기

## 논블로킹 IO는 왜 필요할까

- 경량 스레드 자체도 메모리를 사용하고 스케줄링이 필요하다.
- 경량 스레드가 많이질수록 더 많은 메모리를 사용하고 스케줄링에 더 많은 시간을 사용하게 된다.
- 때문에 경량 스레드로도 한계가 온다.
- 이때 서버의 IO 구현 방식을 구조적으로 변경해야 한다. 즉, 논블로킹IO를 사용해야 하는 것.

## 논블로킹 IO 동작 개요

- 논블로킹 IO는 입출력이 끝날 때까지 스레드가 대기하지 않는다.
- 대기하지 않고 바로 다음 코드를 실행하므로 블로킹IO처럼 데이터를 조회했다는 가정하에 코드를 작성할 수 없다.
- 논블로킹 IO를 사용할 떄는 데이터 읽기를 바로 시도하기보다는 어떤 연산을 수행할 수 있는지 확인하고 해당 연산을 실행하는 방식으로 구현한다.
- 일반적으로 블로킹 IO로 구현한 서버는 커넥션별 스레드를 할당하는 반면
  논블로킹 IO는 클라이언트 수에 상관없이 소수의 스레드를 사용한다.
- 동시 접속하는 클라이언트가 증가해도 스레드 개수는 일정하게 유지되므로 같은 메모리로 더 많은 클라이언트 연결을 처리할 수 있다.

> IO 멀티플렉싱
우리말로 IO 다중화 단일 이벤트 루프에서 여러 IO 작업을 처리하는 개념을 표현할 때 사용
IO 멀티플렉싱을 사용함으로써 더 적원 자원(메모리, CPU)으로 더 많은 클라리언트를 처리할 수 있어 대규모 트래픽을 처리해야 하는 서버를 구현할 때 IO 멀티플렉싱을 사용한다.
>

## 논블로킹 IO에서 동시성을 높이기 위해 사용하는 방법

- 채널들을 N개의 그룹으로 나눈뒤 각 그룹마다 스레드를 생성
- 보통 CPU 개수만큼 그룹을 나누고 각 그룹마다 입출력을 처리할 스레드를 할당

## 리액터 패턴

- 논블로킹 IO를 이용해서 구현할 때 사용하는 패턴 중 하나
- 동시에 들어오는 여러 이벤트를 처리하기 위한 이벤트 처리 방법
- 리액터와 핸들러 두 요소로 구성
- 리액터는 이벤트가 발생할 떄까지 대기하다가 이벤트가 발생하면 알맞은 핸들러에 이벤트를 전달
- 이벤트를 받은 핸들러는 필요한 로직을 수행

- 이벤트 루프는 단일 스레드로 실행
    - 멀티 코어를 가진 서버에서 단일 스레드만 사용하면 처리량을 최대한 낼 수 없다.
- 핸들러에서 CPU연산이나 블로킹을 유발하는 연산을 수행하면 그 시간만큼 전체 이벤트 처리 시간이 지연된다.
    - 이런 한계를 보완하기 위해 핸들러나 블로킹 연산을 별도 스레드 풀에서 실행하기도 한다.
    - Netty는 여러개의 이벤트루프를 생성해서 멀티 코어를 활용
    - Node.js는 이벤트 루프 외에 별도의 스레드 풀을 사용해서 CPU 중심 작업이나 블로킹 연산을 동시에 처리.

## 언제 어떤 방법을 택할까

### 논블로킹 IO나 가상 스레드를 적용할 때 검토할 부분

- 문제가 있는가?
- 문제가 있다면 네트워크 IO 관련 성능 문제인가?
- 구현 변경이 가능한가?

**성능 최적화 접근법의 우선순위**

**1단계: 성능 문제 존재 여부 확인**

- 성능 문제가 없거나 트래픽 증가 가능성이 없다면 논블로킹 IO나 가상 스레드 도입 불필요
- 불필요한 구현 변경은 코드 복잡성만 증가시키고 유지보수를 어렵게 만듦

**2단계: 문제 원인 분석**

- 성능 문제가 네트워크 IO 관련인지 확인 필요
- DB 쿼리 최적화나 CPU 집약적 작업은 논블로킹 IO로 해결되지 않음
- 적절한 해결책: DB 쿼리 최적화, 캐시 활용 등

**3단계: 구현 변경 가능성 검토**

- **기술적 가능성**: 가상 스레드 적용 가능 여부
- **우선순위**: 신기능 개발 vs 성능 개선 인력 배분
- **기술적 숙련도**: 개발팀의 관련 기술 이해도

**결론**
문제 존재 + IO 관련 문제 + 구현 변경 가능한 상황에서만 논블로킹 IO나 가상 스레드 적용을 고려해야 함. 그렇지 않은 경우 서버 확장 등 다른 방법으로 해결하는 것이 현실적임.