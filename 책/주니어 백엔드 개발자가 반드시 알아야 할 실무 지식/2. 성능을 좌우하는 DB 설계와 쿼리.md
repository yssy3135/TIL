### 조회 트래픽을 고려한 인덱스 설계

- DB 테이블을 설계할 때는 조회 기능과 트래픽 규모를 고려해야 한다.
- 풀 스캔이 발생하지 않도록 조회 패턴을 기준으로 인덱스를 설계해야 한다.

**풀스캔**

- 테이블의 모든 데이터를 순차적으로 읽는것
- where 조건에 대응하는 인덱스가 없을 때 발생
- 인덱스를 사용하는 것 보다 전체 데이터를 탐색하는 것이 더 빠를 때도 풀 스캔이 발생
- 데이터 개수가 적을떄 풀스캔 성능 문제가 겉으로 드러나지 않지만 데이터 개수가 늘어나면 응답 시간이 기하급수적으로 증가하게 된다

**단일 인덱스와 복합 인덱스**

- 사용자당 가질 수 있는 데이터가 얼마나 될지 가늠해보면 어던 인덱스를 사용해야 할지 판단하는 데 도움이 된다.
- 데이터가 적으면 Id같은 단일 인덱스만 사용해도 심각한 문제는 발생하지 않는다.
- 사용자당 수만 건이 넘는 데이터가 존재한다면 Date컬럼과 같은 복합 인덱스로 생성해야 조회 성능 문제가 발생하지 않는다.

**선택도를 고려한 인덱스 컬럼 선택**

- 인덱스를 생성할 때는 선택도가 높은 컬럼을 골라야 한다.
    - 선택도는 인덱스에서 특정 칼럼의 고유한 값 비율
- 선택도가 높을수록 인덱스를 이용한 조회 효율이 높아진다.

**커버링 인덱스**

- 특정 쿼리를 실행하는데 필요한 컬럼을 모두 포함하는 인덱스
- 커버링 인덱스를 사용하면 쿼리 실행 효율을 높일 수 있다.
- 실제 데이터에 접근하지 않고 실제 데이터를 읽어오는 과정이 생략되기 때문에 쿼리 실행 시간이 빨라진다.

**인덱스는 필요한 만큼만 만들기**

- 효과가 적인 인덱스를 추가하면 오히려 성능이 나빠질 수 있다.
- 인덱스는 조회 속도를 빠르게 해주지만 데이터 추가, 변경, 삭제시에는 인덱스 관리에 따른 비용 (시간)이 추가되기 때문
- 인덱스 자체도 데이터이기 때문에 인덱스가 많아질수록 메모리와 디스크 사용량도 함께 증가한다.
- 같은 컬럼을 사용하는 인덱스를 중복으로 추가하지 말자
    - 조회 성능이 두 배로 좋아지거나 하지 않는다
    - 인덱스 관리 비용만 증가할 뿐

**몇 가지 조회 성능 개선 방법**

- 집계 데이터를 미리 계산해서 별도 컬럼에 저장하면 된다?
    - *생각) 언제 어떻게 미리 계산해서 저장할 것인가?*
        - 비정규화 하여  카운트 개수를 보관해준다.

**비정규화 해도 괜찮나요?**

- 약간의 불일치를 감수하더라도 집계용 컬럼을 추가하는 것은 맞다고 생각.
    - 목록을 보는 클라이언트에게는 중요한 문제가 아니기 때문
- 정확한 값은 언제든지 구할 수 있다!

**페이지 기준 목록 조회 대신 ID 기준 목록 조회 방식 사용하기**

- 오프셋을 사용했을 때는 지정한 오프세만큼 데이터를 세는 시간이 필요한데 이 과정이 생략되어 실행 시간이 빠르다.
- 모바일 화면에서 마지막으로 조회한 ID를 기준으로 다음 데이터를 요청함으로써 조회 속도를 높일 수 있다.

**조회 범위를 시간 기준으로 제한하기**

**전체 개수 세지 않기**

- 데이터가 많아질수록 count 실행 시간도 증가한다.
    - 조건에 해당하는 모든 데이터를 탬색해야 하기 때문
- 커버링 인덱스를 사용하더라도 전체 인덱스를 스캔해야 한다, 커버링 인덱스가 아닌 경우에는 실제 데이터를 전부 읽어야 한다.
- 조회 속도가 느려지는데 원인 중 하나가 전체 개수를 세는 쿼리에 있다면 해당 쿼리를 실행하지 않는 방법을 고려해야 한다.

**오래된 데이터 삭제 및 분리 보관하기.**

- 데이터 개수가 늘어나면 쿼리 실행 시간은 증가한다.
    - 즉, 데이터 개수가 증가하지 않으면 실행 시간을 일정 수준으로 유지 할 수 있음.
- 데이터 증가 폭을 낮추는 방법 중 하나는 과거 데이터를 삭제하는 것

> 단편화와 최적화
Delete 쿼리를 이용해 테이블에서 데이터를 삭제해도 실제 DB가 사용하는 디스크 용량은 줄어들지 않는다.
DB는 해당 데이터가 삭제되었다는 표시만 남기고, 삭제된 공간은 향후 재사용한다.

**데이터가 반복적으로 추가되고 제거되는 과정에서 데이터가 흩어져 저장되고 빈 공간이 생기는 단편화 현상이 발생 할 수 있다.**
>
>
> 단편화가 심해지면 디스크 I/O가 증가하면서 쿼리 성능이 저하될 수 있다.
> 또한 테이블에 실제로 보관된 데이터 크기보다 더 많은 디스크 공간을 사용하게 되어, 디스크 낭비도 발생한다.
> 단편화로 인한 성능 저하를 해결하는 방법 중 하나는 최적화 작업이다. 최적화는 데이터를 재배치해 단편화를 줄이고, 물리적인 디스크 사용량까지 줄여주는 효과가 있다.
>

**DB 장비 확보하기**

- 클라우드를 사용하면 DB 장비의 성능을 짧은 시간안에 높일 수 있다.
    - 일단 버틸 수 있는 상태를 만들고 효과적인 개선 방안을 찾아 적용하자
- 수평으로 확장하면 DB가 처리할 수 있는 트래픽을 늘릴 수 있다.
    - Primary-Replica 구조를 사용해 처리량을 효과적으로 증가시킬 수 있다.
    - 변경 쿼리는 Primary 조회 쿼리는 replica를 통해 실행

**별도 캐시서버 구성**

- DB만으로 모든 트래픽을 처리하기 어려워질 수 있다.
- 캐시 서버를 잘 활용하면 DB 확장 대비 적은 비용으로 더 많은 트래픽을 처리할 수 있다.
- 캐시를 도입하려면 코드를 수정해야 하지만, 코드 수정에 드는 비용 대비 캐시로 증가 시킬 수 있는 처리량이 크다면, 코드를 수정하는 것이 더 합리적인 선택이다.

### 알아두면 좋을 몇 가지 주의 사항

**쿼리 타임아웃**

- 응답시간이 길어지면 처리량은 감소하는데, 응답 지연으로 인한 재시도는 서버 부하를 더욱 가중시킴
    - 재시도가 반복되면 동시에 처리해야 하는 요청 수가 기하급수적으로 늘어나고 서버 부하는 폭증한다.
- 상황을 방지하기 위해 쿼리 실행 시간을 제한(타임아웃 설정) 하는 것.
    - 사용자가 재시도를 하더라도 이전 요청이 여전히 처리중인 상태가 아니므로 동시 요청 수의 폭증을 막을 수 있다.
- 쿼리 타임아웃은 서비스와 기능의 특성에  따라 다르게 설정해야 함.
    - 블로그 글을 조회같은 단순 조회는 짧게 설정해도 무관.
    - 결제 처리 중 타임아웃으로 에러가 발생하면 후속 처리와 데이터 정합성이 복잡해질 수 있음.

**상태 변경 기능은 복제 DB에서 조회하지 않기.**

- 주DB와 복제DB 간 데이터가 순간적으로 일치하지 않을 수 있다.
- 트랜잭션 문제가 발생할 수 있다.
    - 주 DB와 복제 DB 간 데이터 복제는 트랜잭션 커밋 시점에 이루어짐.
    - 주 DB의 트랜잭션 범위 내에서 데이터를 변경하고, 복제 DB에서 변경 대상이 될 수 있는 데이터를 조회하면 데이터 불일치로 문제가 생길 수 있다.

**배치 쿼리 실행 시간 증가**

한번에 조회하고 집계하는 데이터가 많아질수록 일괄 처리용 쿼리의 실행 시간도 함께 증가한다.

집계 쿼리는 큰 폭으로 증가했는지를 감지할 수 있고, 문제가 되는 쿼리를 발견하면 원인을 찾아 해결할 수 있다.

가장 빠른 해결책은 DB 장비의 사양을 높이는 것.

하지만 항상 가능한 것이 아님 다른 방법을 함께 고려해야 한다.

- 커버링 인덱스 활용
    - 집계 쿼리는 특성상 많은 데이터를 스캔한다.
    - 커버링 인덱스를 활용하면 처리 속도는 빨라지고 DB가 사용하는 메모리도 줄어든다.
- 데이터를 일정 크기로 나눠 처리

- 특정 시간 구간에 포함된 모든 접속 로그 데이터를 대상으로 집계 하는 경우
    - 컬럼에 인덱스를 추가하더라도 데이터 개수가 많아지면 실행에 시간이 오래 걸릴 수 있다.
    - 쿼리를 시간 구견별로 나눠 실행하면 적어도 겨로가를 끊김없이 구할 수 있다.

**타입이 다른 컬럼 조인 주의**

- 타입이 다른 두 컬럼을 비교하는 과정에서 DB는 타입변환을 수행한다.
- 타입변환은 각 행마다 발생하며 결과적으로 인덱스를 온전히 활용하지 못한다.
- 비교 대상 컬럼의 타입을 맞추면 쿼리 실행 중 발생하는 불필요한 타입 변환을 줄일 수 있고 실행 시간이 길어지는 문제도 방지할 수 있다.

> 문자열 타입을 비교할 때는 컬럼의 캐릭터셋이 같은지 확인해야 한다.
캐릭터셋이 다르면 그 자체로도 변환이 발생 할 수 있기 때문이다.
>

**테이블 변경은 신중하게**

- 테이블을 변경할 때 새 테이블을 생성하고 원본 테이블의 데이터를 복사한 뒤, 복사가 완료되면 새 테이블로 대체한다.
- 복사 과정에서 UPDATE, INSERT, DELETE 같은 DML작업을 허용하지 않기 때문에 복사 시간만큼 서비스가 멈춘다.

**DB 최대 연결 개수**

- DB 서버 자원에는 여유가 있지만 API 서버에서 DB에 연결되지 않는다면 DB에 설정된 최대 연결 개수를 확인해야 한다.
    - api 서버 개수가 30개 일때 4대로 늘리면 필요한 컨넥션 개수는 120개, DB는 100개 까지 연결을 허용한다고 하면 20개의 커넥션을 얻지 못하고 연결 실패가 발생하게 된다.
    - DB의 최대 연결 개수를 늘려주는 것만으로도 문제를 해결할 수 있다.
- DB 서버의 CPU 사용률이 70%이상으로 높다면 연결 개수를 늘리면 안된다.
    - 연결 수가 많아질수록 DB 부하는 증가하고 성능 저하가 발생할 수 있다.
    - 캐시 서버 구성이나 쿼리 튜닝 같은 조치를 통해 DB 부하를 낮추고 필요할 떄 연결 개수를 늘려야 한다.

**실패와 트랜잭션 고려하기**

- 모든 코드가 항상 정상적으로 동작하는 것은 아니기 때문에 비정상 상황에서의 트랜잭션 처리를 반드시 고민해야 한다.